 # Config for training ALAE on FFHQ at resolution 1024x1024

NAME: ecog
DATASET:
  PART_COUNT: 16
  SIZE: 60000
  FFHQ_SOURCE: /data/datasets/ffhq-dataset/tfrecords/ffhq/ffhq-r%02d.tfrecords
  PATH: /data/datasets/ffhq-dataset_new/tfrecords/ffhq/splitted/ffhq-r%02d.tfrecords.%03d

  FLIP_IMAGES: False

  PART_COUNT_TEST: 4
  PATH_TEST: /data/datasets/ffhq-dataset_new/tfrecords/ffhq-test/splitted/ffhq-r%02d.tfrecords.%03d

  SAMPLES_PATH: ''
  STYLE_MIX_PATH: style_mixing/test_images/set_ecog
  SPEC_CHANS: 64
  TEMPORAL_SAMPLES: 128
  BCTS: True
  MAX_RESOLUTION_LEVEL: 7
  SUBJECT: ['NY742']
  SELECTREGION: ["AUDITORY","BROCA","MOTO","SENSORY"]
  # SELECTREGION: ["AUDITORY"]
  BLOCKREGION: []
  PROD: True
  PRE_ARTICULATE: False
  TRIM: True
  DENSITY: 'HB'
MODEL:
  #####TAKE OFF CHECKLIST!!!########
  N_FORMANTS: 6
  N_FORMANTS_NOISE: 1
  N_FORMANTS_ECOG: 6
  WAVE_BASED : True
  DO_MEL_GUIDE : False 
  BGNOISE_FROMDATA: True
  N_FFT : 256
  NOISE_DB : -50 #-50
  MAX_DB : 22.5 #probablity 28 is better
  NOISE_DB_AMP : -25
  MAX_DB_AMP : 14
  POWER_SYNTH: True
  NORMED_MASK: True
  DUMMY_FORMANT: False
  CAUSAL: False
  ANTICAUSAL: False
  LEARNED_MASK: False
  N_FILTER_SAMPLES: 20

  LESS_TEMPORAL_FEATURE: True
  LATENT_SPACE_SIZE: 128
  LAYER_COUNT: 6
  MAX_CHANNEL_COUNT: 512
  START_CHANNEL_COUNT: 16
  DLATENT_AVG_BETA: 0.995
  MAPPING_LAYERS: 8
  TRUNCATIOM_CUTOFF: 5
  CHANNELS: 1
  UNIQ_WORDS: 50
  #MAPPING_FROM_ECOG: "ECoGMappingBottleneck"  #ECoGMappingBottlenecklstm1, ECoGMappingBottlenecklstm2
  #MAPPING_FROM_ECOG: "ECoGMappingBottlenecklstm1"
  MAPPING_FROM_ECOG: "ECoGMappingBottleneck_ran"
  #MAPPING_FROM_ECOG: "ECoGMappingBottlenecklstm_pure"
  ONEDCONFIRST: True
  RNN_TYPE: 'LSTM'
  RNN_LAYERS: 4
  RNN_COMPUTE_DB_LOUDNESS: True
  BIDIRECTION: True
  EXPERIMENT_KEY: 0
  # MAPPING_FROM_ECOG: "ECoGMappingTransformer"
  ECOG: False #will be overloaded if FINETUNE
  SUPLOSS_ON_ECOGF: False # will be overloaded to FIX_GEN if FINETUNE,spec supervise loss only apply to ecog encoder
  W_SUP: False
  GAN: True
  GENERATOR: "GeneratorFormant"
  ENCODER: "EncoderFormant"
  AVERAGE_W: True
  TEMPORAL_W: True
  GLOBAL_W: True
  TEMPORAL_GLOBAL_CAT: True
  RESIDUAL: True
  W_CLASSIFIER: False
  CYCLE: False
  ATTENTIONAL_STYLE: True
  #T            4      8      16    32    64    128 
  ATTENTION: [False, False, False, False, False, False]
  HEADS: 1
  APPLY_PPL: False 
  APPLY_PPL_D: False
  PPL_WEIGHT: 100
  PPL_GLOBAL_WEIGHT: 0
  PPLD_WEIGHT: 1
  PPLD_GLOBAL_WEIGHT: 0
  COMMON_Z: True
  PHONEMEWEIGHT: 1
  ld_loss_weight: True
  alpha_loss_weight: True
  consonant_loss_weight: False
  component_regression: False
  amp_formant_loss_weight: False
  freq_single_formant_loss_weight: False
  amp_minmax: False
  amp_energy: False
  f0_midi: False
  alpha_db: False
  network_db: False
  consistency_loss: False
  delta_time: False
  delta_freq: False
  cumsum: False
  distill: False
  classic_pe: False
  temporal_down_before: False
  conv_method: "both"
  classic_attention: True
  rdropout: 0





  TRANSFORMER:
    HIDDEN_DIM : 256
    DIM_FEEDFORWARD : 256
    ENCODER_ONLY : False
    ATTENTIONAL_MASK : False
    N_HEADS : 4
    NON_LOCAL: True
    FASTATTENTYPE: "full"
  # ATTENTION: []
#OUTPUT_DIR: output/ecog_10241800_lstm1 #training_artifacts/debug
#OUTPUT_DIR: output/ecog_10241800_lstm2
#OUTPUT_DIR: output/ecog_11011800_conv #after change loudness encoder
#OUTPUT_DIR: output/ecog_11011800_lstm1 #after change loudness encoder
OUTPUT_DIR: output/ecog_11021800_lstm1 #after change loudness encoder
# OUTPUT_DIR: training_artifacts/loudnesscomp_han5_ampamploss
# OUTPUT_DIR: training_artifacts/loudnesscomp_han5_ampsynth_masknormed
# OUTPUT_DIR: training_artifacts/debug_f1f2linearmel
# OUTPUT_DIR: training_artifacts/ecog_finetune_3ecogformants_han5_specsup_guidance_hamonicformantsemph
# OUTPUT_DIR: training_artifacts/ecog_finetune_3ecogformants_han5_specsup_guidance_hamonicnoiseformantsemphmore
# OUTPUT_DIR: training_artifacts/formantsythv2_wavebased_NY742_constraintonFB_Bconstrainrefined_absfreq_4formants_1noiseformants_bgnoise_noisemapping_freqconv_duomask
# OUTPUT_DIR: training_artifacts/ecog_residual_latent128_temporal_lesstemporalfeature_noprogressive_HBw_ppl_ppld_localreg_ecogf_w_spec_sup
# OUTPUT_DIR: training_artifacts/ecog_residual_latent128_temporal_lesstemporalfeature_ppl_ppld
# OUTPUT_DIR: training_artifacts/ecog_residual_cycle_attention3264wStyleIN_specchan64_more_attentfeatures_heads4
FINETUNE:
  FINETUNE: True
  FIX_GEN: True
  ENCODER_GUIDE: True
  SPECSUP: True
  APPLY_FLOODING: True

VISUAL:
  VISUAL: False
  KEY: 'freq_formants_hamon'
  INDEX: [0]
  A2A: False

#####################################

TRAIN:
  PROGRESSIVE: False
  W_WEIGHT: 1
  CYCLE_WEIGHT: 1
  BASE_LEARNING_RATE: 0.002
  EPOCHS_PER_LOD: 16
  LEARNING_DECAY_RATE: 0.1
  LEARNING_DECAY_STEPS: [96]
  TRAIN_EPOCHS: 100
  #                    4    8   16    32    64    128    256
  LOD_2_BATCH_8GPU: [512, 256, 128,   64,   32,    32] # If GPU memory ~16GB reduce last number from 32 to 24
  LOD_2_BATCH_4GPU: [64, 64, 64,   64,   32,    16]
  LOD_2_BATCH_2GPU: [64, 64, 64,   64,   32,    16]
  # LOD_2_BATCH_1GPU: [512, 256, 128,   64,   32,    16]
  # LOD_2_BATCH_1GPU: [512, 256, 128,   64,   32,    32]
  # LOD_2_BATCH_1GPU: [512, 256, 128,   64,   32,    16]
  # LOD_2_BATCH_1GPU: [128, 128, 128,   128,   64,    32]
  # LOD_2_BATCH_1GPU: [512, 256, 256,   128,   64,    16]
  LOD_2_BATCH_1GPU: [64, 64, 64,   64,   32,    16]
  BATCH_SIZE : 4
  # BATCH_SIZE : 2
  LEARNING_RATES: [0.0015,  0.0015,   0.0015,    0.002,     0.003,    0.003]
  # LEARNING_RATES: [0.0015,  0.0015,   0.0005,    0.0003,     0.0003,    0.0002]
